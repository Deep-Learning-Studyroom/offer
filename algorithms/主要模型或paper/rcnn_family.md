# R-CNN系列文章总结
后面将重新阅读R-CNN系列的文章，从模型的创新、应用两方面进行总结。

# R-CNN
## 贡献
R-CNN是第一个在VOC等数据上获得巨大map提升的以CNN为基础的模型（VOC2012上达到了53%），它的主要贡献在于：
1. 在two-stage的cnn base检测算法中，换掉了之前已经使用了至少二十年的sliding-window的提取ROI方式，改用selective-search。因为滑动窗
的窗口固定，实际上限制了感受野，即检测器对目标尺度很敏感，而用ss的方式再resize给网络实际上为模型引入了尺度信息。文章提到用这种方法感受野
提到了195X195，输入是227X227
2. 使用分类问题的预训练模型进行fine-tuning，使map提升了八个点。（解决了标注了box的数据不足的问题）
3. 用回归来修正proposal，提升了3-4个点。
4. 总的来说，提出了一个完整的pipeline，使模型的capacity变大了，然后利用low-level信息来定位，利用high-level信息来分类，也符合浅层位置
信息，深层语义信息的道理。

## 测试过程（forward）
先在ss中得到2000个region proposals，然后将它们resize到固定大小送入cnn，cnn将每个proposal的feature map提取成一个4096维的向量，再通过一个SVM进行分类（SVM的权重矩阵维度是4096 X N， N是类别数目）。
最后对预测出的框做NMS（分别对不同的类别）

## 训练过程
1. 对CNN进行其他数据集的分类预训练。
2. 将预训练好的分类网络拿来用目标检测数据进行分类微调，模型输入是resize后的proposals，输出是（N+1）维，其中N是类别数目，1代表背景。也就是让cnn具有区分N个目标和背景的能力。
label的分配方法是将与gt的iou大于0.5的作正例，其他的都为负例，训练使用SGD，步长为0.001（只有分类预训练时的10%）
3. 上一步训练的batch_size是128.其中分为32个positive（包含了所有类别），96个negative，这是更好锻炼模型区分背景与目标的能力，以提取出有效信息供SVM使用。并且训练时对positive的例子做了一些偏移，为了使这些具有目标的区域也能包含一些背景。
4. 最后训练N个SVM来分类，其中预测的框与某个类别的gt的iou只要大于0.3，就将这个框分配这个类别的label。因为对每个class都训练一个svm很费时间，所以作者选用了对各个class的hard negative的例子来作为训练数据，这样既能提升时间、又能保证性能。

## 疑问
虽然在对cnn进行微调时，有针对背景去分类，但是最后是用的SVM，并没有使用CNN的分类器，那么模型是在哪一步确认这个ROI是不是背景的？ 难道是当每个SVM的输出都是no时，这个框就是背景吗？

## 不足
1. SS的速度很慢，几十秒一张图
2. 对每个类别各训练一个SVM不是很好




