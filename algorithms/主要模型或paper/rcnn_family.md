# R-CNN系列文章总结
后面将重新阅读R-CNN系列的文章，从模型的创新、应用两方面进行总结。

# R-CNN
## 贡献
R-CNN是第一个在VOC等数据上获得巨大map提升的以CNN为基础的模型（VOC2012上达到了53%），它的主要贡献在于：
1. 在two-stage的cnn base检测算法中，换掉了之前已经使用了至少二十年的sliding-window的提取ROI方式，改用selective-search。因为滑动窗
的窗口固定，实际上限制了感受野，即检测器对目标尺度很敏感，而用ss的方式再resize给网络实际上为模型引入了尺度信息。文章提到用这种方法感受野
提到了195X195，输入是227X227
2. 使用分类问题的预训练模型进行fine-tuning，使map提升了八个点。（解决了标注了box的数据不足的问题）
3. 用回归来修正proposal，提升了3-4个点。
4. 总的来说，提出了一个完整的pipeline，使模型的capacity变大了，然后利用low-level信息来定位，利用high-level信息来分类，也符合浅层位置
信息，深层语义信息的道理。

## 测试过程（forward）
先在ss中得到2000个region proposals，然后将它们resize到固定大小送入cnn，cnn将每个proposal的feature map提取成一个4096维的向量，再通过一个SVM进行分类（SVM的权重矩阵维度是4096 X N， N是类别数目）。
最后对预测出的框做NMS（分别对不同的类别）

## 训练过程
1. 对CNN进行其他数据集的分类预训练。
2. 将预训练好的分类网络拿来用目标检测数据进行分类微调，模型输入是resize后的proposals，输出是（N+1）维，其中N是类别数目，1代表背景。也就是让cnn具有区分N个目标和背景的能力。
label的分配方法是将与gt的iou大于0.5的作正例，其他的都为负例，训练使用SGD，步长为0.001（只有分类预训练时的10%）
3. 上一步训练的batch_size是128.其中分为32个positive（包含了所有类别），96个negative，这是更好锻炼模型区分背景与目标的能力，以提取出有效信息供SVM使用。并且训练时对positive的例子做了一些偏移，为了使这些具有目标的区域也能包含一些背景。
4. 最后训练N个SVM来分类，其中预测的框与某个类别的gt的iou只要大于0.3，就将这个框分配这个类别的label。因为对每个class都训练一个svm很费时间，所以作者选用了对各个class的hard negative的例子来作为训练数据，这样既能提升时间、又能保证性能。

## 疑问
虽然在对cnn进行微调时，有针对背景去分类，但是最后是用的SVM，并没有使用CNN的分类器，那么模型是在哪一步确认这个ROI是不是背景的？ 难道是当每个SVM的输出都是no时，这个框就是背景吗？

## 不足
1. SS的速度很慢，几十秒一张图
2. 对每个类别各训练一个SVM不是很好

# Fast R-CNN
## 主要贡献：
1. R-CNN与SPPnet中，训练很复杂。如先进行fine-tuning训练了一个分类器，却又不用这个分类器最后的softmax部分，而是另外训练SVM，这样就很浪费。并且对回归和分类两个部分是分别训练的，整个pipeline比较复杂。针对这个问题，Fast R-CNN去除了SVM，直接使用fine tuning的softmax作为分类器，并且将回归和分类使用一个multi-loss来训练，这样流程就简洁了许多。
2. 在R-CNN和SPPnet中，模型每得到一个ROI，都要用CNN计算一次，实际上一张图的同一部分可能重复计算了很多次。所以Fast R-CNN将VGG16挪到了流程的最开始，然后引入ROI pool来寻找ROI在卷积后的feature map上对应的位置。通过这种方式，每张图就只需要经过一次backbone了。
## 细节
1. ROIPOOL：
ROIPOOL是由SPPnet的做法改进而来。在SPPnet中，最后ROI的每一个feature map都被划分成4x4、2x2、1x1三种网格结构，然后对每个网格进行max pooling，再将所有maxpooling的数字堆叠成一维向量。而roipool的做法是将roi投影到卷积后的feature map上，然后将这块区域划分成7x7网格，然后对每个网格做max pool，这样进入后续网络的feature map尺寸就统一了。
2. fine-tuning：将imagenet预训练的模型最后的全连接层移除，换成回归和分类的两个分支，其中分类有K+1个类别，K为类别数。注意网络的输入有两个：图像的list和这些图ROIs的list
3. 模型的训练每个batch采用N=2、R=128，其中N代表图像数、R代表ROI的数量。
4. 回归时，模型得出的是偏移量tx、ty、tw、th，偏移量的形式给模型带来了放缩不变性。
$$L(p, u, tu, v) = Lcls(p, u) + λ[u ≥ 1]Lloc(tu, v)$$
其中分类部分是-log，u>=1代表只训练非背景样本。
并且回归函数中，将偏移量的label：v归一化为0均值、1方差
。使用smooth函数来做回归，使得反向传播时参数在差值接近0的地方，可以更缓慢地学习，也解决了y=|x|在零点不能求导的问题。
5. 正负例的采样：与gt的iou大于0.5的标正例，（0.1，0.5）区间内的作为负例，原文说这个0.1的阈值是为了挖掘hard example的启发式搜索，所以小于0.1的样本应该是不要了。
6. 分类和回归的分支中，参数的初始化分别使用了标准差为0.01和0.001的零均值高斯分布，bias初始化为0
7. scale invariance： 做了两件事，一件是把每个输入暴力resize成固定尺寸，使模型的输入尺寸一致，学习更稳定。另一件是引入图像金字塔，即把每张图resize成各个尺寸的图，组成金字塔，然后每次随机地抽取一张（受到内存限制），这实际上也是数据增强的一种形式。
8. 对每一类的roi都会做topk的nms。


