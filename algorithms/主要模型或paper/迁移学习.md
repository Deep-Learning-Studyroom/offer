# 知识蒸馏

## Hinton 2015年的论文《Distilling the Knowledge in a Neural Nerwork》

模型训练阶段我们一般不考虑部署的问题，因此会使用很大的网络或者集成很多大的网络来得到最好的模型performance。但是在模型部署的时候我们需要更小的模型，一方面可以减少存储空间，一方面可以提高推理速度。这些因素在实际应用中都是很重要的。

