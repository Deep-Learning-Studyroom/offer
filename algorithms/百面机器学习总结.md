# 百面机器学习总结

主要总结一些之前没太注意的地方，本书对于NLP领域的知识我不会太过重视，所以也不会有很多NLP的总结。

## 第一章 特征工程

1. 数据归一化问题中，通过梯度下降法优化的算法通常是需要归一化的。但对于决策树模型，归一化不适用。这是因为归一化对信息增益比这类指标的求取不会有影响。
2. one-hot编码有一个很重要的点在于它可以使用稀疏向量来节省空间，比如只给模型这个向量的长度以及取值为1的坐标。另外因为one-hot中一个维度对应一个特征的关系，特征选择后可以直接降低one-hot编码的维度。
3. 模型学习来源一般是两个：数据中的信息、人为给的先验信息。先验信息可以是加在模型里、也可以是加在数据里。比如对图像做灰度上的预处理，加强某些地方，就是把先验知识加在了数据里。把觉得重要的地方放在模型里作为attention，那就是把先验知识加在了模型中。
4. 一般过拟合的处理方式是正则化或者数据扩充，数据扩充的诸多方式中除了旋转等扰动外，还可以做颜色变化。比如求每个像素点的Hessian矩阵，再求其特征值$\lambda$与特征向量$\eta$，取得特征值最大的一组，将原图每个像素点施加一个$\lambda\cdot\eta\cdot\alpha$，其中$\alpha$是一个均值为0，方差较小的高斯分布随机数。 

## 第二章 模型评估

1. ROC曲线与P-R曲线，本质上都是为了权衡模型在不同阈值下的性能。ROC曲线的直观感受是：希望模型就算误报、也尽量不要漏报（横轴是FPR，纵轴是TPR也就是召回率）。P-R曲线便是precision和recall之间直接的一种trade-off。ROC曲线随着数据集大量负例的增加不会有什么变化，因为ROC的纵轴是召回率，负例的增加是几乎不会影响召回率的，这一点从召回率的公式能看出。P-R曲线由于纵轴是precision，所以会受大量FP的影响。ROC能更好地反映模型本身的好坏，P-R曲线能更直观地反映模型在某数据集上的性能。
2. 为什么ROC曲线中，FPR接近0时，TPR也接近0？   因为FPR接近0，意味着阈值比较高，相应地TP也会减少，FN会增多，所以就造成了这样的结果。