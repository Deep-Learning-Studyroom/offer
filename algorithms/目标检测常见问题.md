# 目标检测综述
## One-stage and Two-stage
当前的目标检测算法，一般被分为one-stage和two-stage
，主要区别于two-stage算法先寻找ROI，再对ROI进行
分类和回归；而one-stage直接同时预测出框的坐标与类别。
two-stage算法的代表是R-CNN系列，one-stage的代表是YOLO和SSD。

## Anchor-base and Anchor-free
另外，最近比较火的anchor-free思想的算法也和
anchor-base思想形成了一组对立，目前我看到的
anchor-free模型都是one-stage的。以one-stage中的SSD
和YoloV1为例。SSD是有锚框假设的，所以它直接预测出来的
是feature map中某一点中各个预设尺度anchor的<b>偏移量</b>。
而YoloV1是anchor-free的，它直接预测出某一点的框的点坐标。

## 采样策略
除了模型的改动外，诸如SNIP和SNIPER这样的通过采样
策略来引入多尺度检测能力的方法也同样被使用。它可以
移除FPN带来的大量参数，使模型兼顾多尺度检测能力和速度。

## 结构
接下来，将按照r-cnn系列、Yolo系列、SSD、其他检测算法的顺序
，重新阅读这些文章，并总结新的感受及发现的问题。


## 评价指标
对于目标检测来说，通常的评价指标有：accuracy，precision，recall，average precision(AP)，mean average precision(mAP)，IoU，ROC+AUC，非极大值抑制(NMS)  
### 混线矩阵、accuracy、p、r
和分类问题一样。
![](https://github.com/Deep-Learning-Studyroom/offer/blob/master/pictures/criteria.jpg)  

### AP和mAP
AP就是Precision-recall 曲线下面的面积，通常来说一个越好的分类器，AP值越高。  
mAP是多个类别AP的平均值。这个mean的意思是对每个类的AP再求平均，得到的就是mAP的值，mAP的大小一定在[0,1]区间，越大越好。该指标是目标检测算法中最重要的一个。  
**在正样本非常少的情况下，PR表现的效果会更好。**

补充一下AP：

AP是某一类别Precision-Recall曲线下的面积，因为我们知道recall和precision实际上是负相关的。所以AP是一种precision和recall的权衡，一般用在检测模型的评估中。 我们假设对某一类别A进行检测， 我们设置一个阈值0.1，检测框的预测置信度大于0.1的认为是A类别的框，反之则不是A类别。 那么这样的话其实会将很多低置信度的非A框当成是A类， 此时模型的recall很高，因为阈值设的低，把基本上所有的框都当做A了。 如果阈值设为比较高的0.9，那么recall会降低，precision会升高， 因为我们只取了置信度非常高框，有很多确实是A框的也被过滤了。    为了解决这种矛盾问题，我们使用不同的阈值，画出对应类别A的precision-recall曲线，然后取这个曲线与x轴的面积作为average precision，对应的直观含义是，  希望随着recall的提高，precision也能保持一定的高数值，那么这样的模型就是一个比较好的模型。 而map是对于不同类别下的ap的平均值。map的计算其实在十几年间VOC、COCO等目标检测竞赛发展中有了不同的计算方式，不仅会基于目标框置信度设置阈值，还会对目标框与ground truth的IOU（交并比）设置阈值。

### IoU
IoU这一值，可以理解为系统预测出来的框与原来图片中标记的框的重合程度。 计算方法即检测结果Detection Result与 Ground Truth 的交集比上它们的并集，即为检测的准确率。  
IOU正是表达这种bounding box和groundtruth的差异的指标。   
![](https://github.com/Deep-Learning-Studyroom/offer/blob/master/pictures/iou.jpg) 
计算IoU的代码如下：  
```python
def iou(x1,y1,w1,h1,x2,y2,w2,y2):
    up = min(y1 + h1 / 2, y2 + h2 / 2)
    down = max(y1 - h1 / 2, y2 - h2 / 2)
    left = max(x1 - w1 / 2, x2 - w2 / 2)
    right = min(x1 + w1 / 2, x2 + w2 / 2)

    if up > down and right > left:
        intersetion = (up - down) * (right - left)
        union = w1 * h1 + w2 * h2 - intersetion
        return intersetion / union
    else:
        return 0
```

### ROC和AUC 
对角线对应于随机猜测模型，而（0,1）对应于所有正例排在所有反例之前的理想模型。曲线越接近左上角，分类器的性能越好。  
ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。  
ROC曲线绘制：

（1）根据每个测试样本属于正样本的概率值从大到小排序；

（2）从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本；

（3）每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。 

当我们将threshold设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当threshold取值越多，ROC曲线越平滑。

AUC（Area Under Curve）即为ROC曲线下的面积。AUC越接近于1，分类器性能越好。  
计算公式：就是求曲线下矩形面积。
$$AUC = \sum^{m}_{i=2}{\frac{(x_{i} - x_{i-1}) * (y_{i} + y_{i+1})}{2}}$$
### NMS
Non-Maximum Suppression就是需要根据score矩阵和region的坐标信息，从中找到置信度比较高的bounding box。对于有重叠在一起的预测框，只保留得分最高的那个。

（1）NMS计算出每一个bounding box的面积，然后根据score进行排序，把score最大的bounding box作为队列中首个要比较的对象；

（2）计算其余bounding box与当前最大score与box的IoU，去除IoU大于设定的阈值的bounding box，保留小的IoU得预测框；

（3）然后重复上面的过程，直至候选bounding box为空。

最终，检测了bounding box的过程中有两个阈值，一个就是IoU，另一个是在过程之后，从候选的bounding box中剔除score小于阈值的bounding box。需要注意的是：Non-Maximum Suppression一次处理一个类别，如果有N个类别，Non-Maximum Suppression就需要执行N次。  
