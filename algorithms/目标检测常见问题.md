# 目标检测综述
## One-stage and Two-stage
当前的目标检测算法，一般被分为one-stage和two-stage
，主要区别于two-stage算法先寻找ROI，再对ROI进行
分类和回归；而one-stage直接同时预测出框的坐标与类别。
two-stage算法的代表是R-CNN系列，one-stage的代表是YOLO和SSD。

## Anchor-base and Anchor-free
另外，最近比较火的anchor-free思想的算法也和
anchor-base思想形成了一组对立，目前我看到的
anchor-free模型都是one-stage的。以one-stage中的SSD
和YoloV1为例。SSD是有锚框假设的，所以它直接预测出来的
是feature map中某一点中各个预设尺度anchor的<b>偏移量</b>。
而YoloV1是anchor-free的，它直接预测出某一点的框的点坐标。

## 采样策略
除了模型的改动外，诸如SNIP和SNIPER这样的通过采样
策略来引入多尺度检测能力的方法也同样被使用。它可以
移除FPN带来的大量参数，使模型兼顾多尺度检测能力和速度。

## 结构
接下来，将按照r-cnn系列、Yolo系列、SSD、其他检测算法的顺序
，重新阅读这些文章，并总结新的感受及发现的问题。


## 评价指标
对于目标检测来说，通常的评价指标有：accuracy，precision，recall，average precision(AP)，mean average precision(mAP)，IoU，ROC+AUC，非极大值抑制(NMS)  
### 混线矩阵、accuracy、p、r
和分类问题一样。
![](https://github.com/Deep-Learning-Studyroom/offer/blob/master/pictures/criteria.jpg)  

### AP和mAP
AP就是Precision-recall 曲线下面的面积，通常来说一个越好的分类器，AP值越高。  
mAP是多个类别AP的平均值。这个mean的意思是对每个类的AP再求平均，得到的就是mAP的值，mAP的大小一定在[0,1]区间，越大越好。该指标是目标检测算法中最重要的一个。  
**在正样本非常少的情况下，PR表现的效果会更好。**

补充一下AP：

AP是某一类别Precision-Recall曲线下的面积，因为我们知道recall和precision实际上是负相关的。所以AP是一种precision和recall的权衡，一般用在检测模型的评估中。 我们假设对某一类别A进行检测， 我们设置一个阈值0.1，检测框的预测置信度大于0.1的认为是A类别的框，反之则不是A类别。 那么这样的话其实会将很多低置信度的非A框当成是A类， 此时模型的recall很高，因为阈值设的低，把基本上所有的框都当做A了。 如果阈值设为比较高的0.9，那么recall会降低，precision会升高， 因为我们只取了置信度非常高框，有很多确实是A框的也被过滤了。    为了解决这种矛盾问题，我们使用不同的阈值，画出对应类别A的precision-recall曲线，然后取这个曲线与x轴的面积作为average precision，对应的直观含义是，  希望随着recall的提高，precision也能保持一定的高数值，那么这样的模型就是一个比较好的模型。 而map是对于不同类别下的ap的平均值。map的计算其实在十几年间VOC、COCO等目标检测竞赛发展中有了不同的计算方式，不仅会基于目标框置信度设置阈值，还会对目标框与ground truth的IOU（交并比）设置阈值。

### IoU
IoU这一值，可以理解为系统预测出来的框与原来图片中标记的框的重合程度。 计算方法即检测结果Detection Result与 Ground Truth 的交集比上它们的并集，即为检测的准确率。  
IOU正是表达这种bounding box和groundtruth的差异的指标。   
![](https://github.com/Deep-Learning-Studyroom/offer/blob/master/pictures/iou.jpg) 
计算IoU的代码如下：  
```python
def iou(x1,y1,w1,h1,x2,y2,w2,h2):
    up = min(y1 + h1 / 2, y2 + h2 / 2)
    down = max(y1 - h1 / 2, y2 - h2 / 2)
    left = max(x1 - w1 / 2, x2 - w2 / 2)
    right = min(x1 + w1 / 2, x2 + w2 / 2)

    if up > down and right > left:
        intersetion = (up - down) * (right - left)
        union = w1 * h1 + w2 * h2 - intersetion
        return intersetion / union
    else:
        return 0
```

### ROC和AUC 
对角线对应于随机猜测模型，而（0,1）对应于所有正例排在所有反例之前的理想模型。曲线越接近左上角，分类器的性能越好。  
ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。  
ROC曲线绘制：

（1）根据每个测试样本属于正样本的概率值从大到小排序；

（2）从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本；

（3）每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。 

当我们将threshold设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当threshold取值越多，ROC曲线越平滑。

AUC（Area Under Curve）即为ROC曲线下的面积。AUC越接近于1，分类器性能越好。  
计算公式：就是求曲线下矩形面积。
$$AUC = \sum^{m}_{i=2}{\frac{(x_{i} - x_{i-1}) * (y_{i} + y_{i+1})}{2}}$$
### NMS

#### 原理

Non-Maximum Suppression就是需要根据score矩阵和region的坐标信息，从中找到置信度比较高的bounding box。对于有重叠在一起的预测框，只保留得分最高的那个。

（1）NMS计算出每一个bounding box的面积，然后根据score进行排序，把score最大的bounding box作为队列中首个要比较的对象；

（2）计算其余bounding box与当前最大score与box的IoU，去除IoU大于设定的阈值的bounding box，保留小的IoU得预测框；

（3）然后重复上面的过程，直至候选bounding box为空。

最终，检测了bounding box的过程中有两个阈值，一个就是IoU，另一个是在过程之后，从候选的bounding box中剔除score小于阈值的bounding box。需要注意的是：Non-Maximum Suppression一次处理一个类别，如果有N个类别，Non-Maximum Suppression就需要执行N次。  

#### NMS代码

[NMS算法详解（附Pytorch实现代码）](https://zhuanlan.zhihu.com/p/54709759)

[NMS三种numpy的实现方法](https://zhuanlan.zhihu.com/p/64423753)

算法的具体实现思路：先对每个框的score进行排序，首先选择第一个，也就是score最高的框，它一定是我们要保留的框。然后拿它和剩下的框进行比较，如果IOU大于一定阈值，说明两者重合度高，应该去掉，这样筛选出的框就是和第一个框重合度低的框，第一次迭代结束。第二次从保留的框中选出score第一的框，重复上述过程直到没有框保留了。

```python
import numpy as np
def nms(dets, thresh):
    """Pure Python NMS baseline."""
    x1 = dets[:, 0]
    y1 = dets[:, 1]
    x2 = dets[:, 2]
    y2 = dets[:, 3]
    scores = dets[:, 4]
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = scores.argsort()[::-1]
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]]）
        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        ovr = inter / (areas[i] + areas[order[1:]] - inter)
        inds = np.where(ovr <= thresh)[0]
        order = order[inds + 1]  # ovr没有和它自己的iou，因此索引是少了一个，要加1
    return keep
```
再精简一些。
```python
def nms(dets, thresh):                   
    areas=np.prod(bbox[:,2:]-bbox[:,:2],axis=1)
    order = scores.argsort()[::-1]
    keep=[]
    while order.size>0:
        i=order[0]
        keep.append(i)
        tl=np.maximum(b[:2],bbox[i+1:,:2])
        br=np.minimum(b[2:],bbox[i+1:,2:])
        inter=np.prod(br-tl,axis=1)*(br>tl).all(axis=1)
        ovr=inter/(areas[order[1:]]+areas[i]-inter)
        inds=np.where(ovr<=thresh)[0]
        order=order[inds+1]
    return keep
```
不排序怎么写。基本思路是，依次遍历每个框，计算这个框与其他框的iou,找到iou大于一定阈值的其他框，因为这个时候不能保证它一定是score最高的框，所以要进行判断，如果它的score小于其他框，那就把它去掉，因为它肯定不是要保留的框。如果它的score大于其他框，那应该保留它，同时可以去掉所有其他框了。最后保留的框就是结果。
```python
def nms(bbox, scores, thresh):
    area=np.prod(bbox[:,2:]-bbox[:,:2],axis=1)
    keep=np.ones(len(bbox),dtype=bool)
    for i, b in enumerate(bbox):
        if(keep[i]==False):
            continue
        tl=np.maximum(b[:2],bbox[i+1:,:2])
        br=np.minimum(b[2:],bbox[i+1:,2:])
        inter=np.prod(br-tl,axis=1)*(br>=tl).all(axis=1)
        iou=ia/(area[i+1:]+area[i]-inter)
        r = [ k for k in np.where(iou>thresh)[0]+i+1 if keep[k]==True]
        if (scores[i]>scores[r]).all():
            keep[r]=False
        else:
            keep[i]=False
    return np.where(keep)[0].astype(np.int32)
```

## FPN的结构

FPN首先有一条自下而上的路径，使得特征图的尺寸不断变小；然后经过一条自上而下的路径，把更抽象，语义更强的高层特征图进行上采样，然后把该特征横向连接至前一层特征，因此高层特征得到加强。其中，横向连接的两层特征在空间尺寸上要相同。这样做应该主要是为了利用底层的定位细节信息。

问题：里面1x1卷积的作用？

因为降采样的路径channel是变化的，上采样的路径channel不变，对应的特征图channel不同，因此需要1x1卷积转换通道。

## Roi pooling 和 Roi align的区别？

Roi pooling是将Bbox所框起来的特征图转换为kxk的特征图，来保证后面的检测分支的输入尺寸一致，但是它有两个缺点。

1. 由于RPN得到的Bbox的坐标值很可能是小数，因此ROI pooling会先将坐标化整，这个过程造成了Bbox的偏移，或者说引入了位置信息的误差。

2. 当Bbox的尺寸不能被k整除时，它也会将划分点坐标化整，造成最后特征图感受野不同，也使得目标的像素信息发生了扭曲。

ROI Align放弃了化整操作，而是直接通过双线性插值获得像素值，且通过这种方法，能使划分的pixel格数更加平均。


## FPN的多个特征图走的是一个检测网络吗？


## FPN多尺度层中的box如何进行ROIpooling？



