[TOC]

# 1.Ray

Ray是一种针对AI应用的分布式框架，论文地址：<https://arxiv.org/abs/1712.05889>

文档地址：<https://ray.readthedocs.io/en/latest/installation.html>

安装方便，直接

```
pip install -U ray
```



它能够比较简单地将一个Tensorflow的训练代码放上它的分布式平台跑起来。只需要在最开始ray.init，然后在模型的上面加@ray.remote，将模型的类声明为一个Actor。调用的时候再使用对象的remote方法调用成员函数，这样的计算过程就会放到redis服务器上的worker执行了。

```python
import ray
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
ray.init(num_gpus=1)

def LeNet5():
    x = tf.placeholder(tf.float32, [None, 784])
    y_ = tf.placeholder(tf.float32, [None, 10])
    x_img = tf.reshape(x, [-1, 28, 28, 1])

    w_conv1 = tf.get_variable("w_conv1", (5, 5, 1, 6), initializer=tf.glorot_uniform_initializer(seed=0))
    w_conv2 = tf.get_variable("w_conv2", (5, 5, 6, 16), initializer=tf.glorot_uniform_initializer(seed=0))
    w_fc1 = tf.get_variable("w_fc1", (400, 120), initializer=tf.glorot_uniform_initializer(seed=0))
    b_fc1 = tf.get_variable("b1", 120, initializer=tf.glorot_uniform_initializer(seed=0))
    w_fc2 = tf.get_variable("w_fc2", (120, 10), initializer=tf.glorot_uniform_initializer(seed=0))
    b_fc2 = tf.get_variable("b2", 10, initializer=tf.glorot_uniform_initializer(seed=0))

    y = tf.nn.conv2d(x_img, w_conv1, strides=[1, 1, 1, 1], padding="SAME")
    y = tf.nn.relu(y)
    y = tf.nn.avg_pool(y, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")
    y = tf.nn.conv2d(y, w_conv2, strides=[1, 1, 1, 1], padding="VALID")
    y = tf.nn.relu(y)
    y = tf.nn.avg_pool(y, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")
    y = tf.layers.flatten(y)  # [400]
    y = tf.matmul(y, w_fc1) + b_fc1
    y = tf.nn.relu(y)
    y = tf.matmul(y, w_fc2) + b_fc2
    tf.nn.dropout(y, 0.5)
    y = tf.nn.relu(y)
    y = tf.nn.softmax(y)

    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    return x, y_, train_step, accuracy

@ray.remote
class Model(object):
    def __init__(self, mnist_data):
        self.mnist = mnist_data
        with tf.Graph().as_default():
            self.x, self.y_, self.train_step, self.accuracy = LeNet5()
            config = tf.ConfigProto(allow_soft_placement=True)
            self.sess = tf.Session(config=config)
            init = tf.global_variables_initializer()
            self.sess.run(init)

    def train(self, num_steps):
        log = []
        for it in range(num_steps):
            batch_xs, batch_ys = self.mnist.train.next_batch(100)
            _, acc = self.sess.run([self.train_step, self.accuracy],
                                              feed_dict={self.x: batch_xs,
                                                         self.y_: batch_ys})
            if it % 50 == 0:
                print("step:{}, the ac is {}".format(it + 1, acc))

    def get_acc(self):
        return self.sess.run(self.accuracy, feed_dict={self.x: 
                                                       self.mnist.test.images,
                                                       self.y_: 
                                                       self.mnist.test.labels})

mnist_data = input_data.read_data_sets("./ministdata/", one_hot=True)
model = Model.remote(mnist_data)
model.train.remote(2000)
acc = ray.get(model.get_acc.remote())
print("Accuracy in the test set is {}.".format(acc))
```

